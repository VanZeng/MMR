import os
import shutil
import random
import pandas as pd
import ast
import json
import torch
from GaussianNoise import apply_noise
from accuracy import compute_metrics
from cambrian.model.builder import load_pretrained_model
from cambrian.utils import disable_torch_init
from cambrian.mm_utils import (
    get_model_name_from_path,
    process_images,
    tokenizer_image_token
)
from cambrian.constants import (
    IMAGE_TOKEN_INDEX,
    DEFAULT_IMAGE_TOKEN,
    DEFAULT_IM_START_TOKEN,
    DEFAULT_IM_END_TOKEN
)
from cambrian.conversation import conv_templates
from datasets import load_dataset
from tqdm import tqdm
from PIL import Image
from datetime import datetime
import glob

############################ å‚æ•°è®¾ç½® ############################
# å®éªŒæ ¸å¿ƒå‚æ•°
MODEL_PATH = "./cambrian-phi3-3b"          
CLEAN_IMAGE_DIR = "./benchmark/benchmark_coco_filtered/images"  
INIT_STRENGTH = 1.2                        
MAX_STRENGTH = 3.0                         
STEP_SIZE = 0.2                            
RESULT_CSV = "./results/robustness.csv"    

# æ¨¡å‹ç”Ÿæˆå‚æ•°
GENERATION_TEMP = 0.2     
TOP_P = 0.9               
NUM_BEAMS = 1             
MAX_TOKENS = 512          

# å®éªŒæ§åˆ¶å‚æ•°
CONV_MODE = "phi3"        
TOLERANCE = 0.05          
RANDOM_SEED = 42          

# å™ªå£°ç”Ÿæˆå‚æ•°
BASE_SIGMA = 20           
MAX_SIGMA = 150           
SIGMA_VARIATION = 0.15    
GAMMA = 1.5               
NUM_EXAMPLES = 5          
#################################################################

# æ•°æ®æ”¶é›†ç»“æ„
experiment_data = {
    'strengths': [],
    'overall_acc': [],
    'count_acc': [],
    'location_acc': []
}

def init_baseline():
    """è®¡ç®—éšæœºåŸºå‡†æ€§èƒ½"""
    df = pd.read_csv('metadata.csv', engine='python', quotechar='"')
    df['choices'] = df['choices'].apply(ast.literal_eval)
    df['correct'] = df['answer'].str.strip('()')
    
    random.seed(RANDOM_SEED)
    df['pred'] = df['choices'].apply(lambda x: random.choice([chr(65+i) for i in range(len(x))]))
    df['correct'] = df['pred'] == df['correct']
    
    return {
        'overall': df['correct'].mean(),
        'count': df[df.sub_task == 'Count']['correct'].mean(),
        'location': df[df.sub_task == 'Relative location']['correct'].mean()
    }

random_baseline = init_baseline()

def build_prompt(line, model_config):
    """æ„å»ºç¬¦åˆå¯¹è¯æ¨¡æ¿çš„æç¤º"""
    qs = f"{line['prompt']}\nAnswer with the option's letter from the given choices directly."
    
    # å¤„ç†å›¾åƒæ ‡è®°
    if line["image"] is not None:
        if model_config.mm_use_im_start_end:
            qs = f"{DEFAULT_IM_START_TOKEN}{DEFAULT_IMAGE_TOKEN}{DEFAULT_IM_END_TOKEN}\n{qs}"
        else:
            qs = f"{DEFAULT_IMAGE_TOKEN}\n{qs}"
    
    # åº”ç”¨å¯¹è¯æ¨¡æ¿
    conv = conv_templates[CONV_MODE].copy()
    conv.append_message(conv.roles[0], qs)
    conv.append_message(conv.roles[1], None)
    return conv.get_prompt()

def process_sample(line, dataset_path, tokenizer, processor, model_config):
    """å¤„ç†å•ä¸ªæ ·æœ¬ï¼ˆä¿®å¤å›¾åƒè·¯å¾„ï¼‰"""
    # æ„å»ºæç¤º
    prompt = build_prompt(line, model_config)
    
    # å›¾åƒå¤„ç†ï¼ˆå…³é”®ä¿®æ”¹ï¼šä»å™ªå£°æ•°æ®é›†åŠ è½½å›¾åƒï¼‰
    image_tensor = image_size = None
    if line["image"] is not None:
        # ä»å½“å‰å™ªå£°æ•°æ®é›†ç›®å½•åŠ è½½å›¾åƒ
        image_dir = os.path.join(dataset_path, "images")
        image_path = os.path.join(image_dir, line["image_id"])
        image = Image.open(image_path).convert('RGB')
        image_tensor = process_images([image], processor, model_config)
        image_size = [image.size]
    
    # Tokenization
    input_ids = tokenizer_image_token(
        prompt, 
        tokenizer, 
        IMAGE_TOKEN_INDEX, 
        return_tensors='pt'
    ).unsqueeze(0).cuda()
    
    return input_ids, image_tensor, image_size, prompt

def evaluate(dataset_path):
    """æ‰§è¡Œæ¨¡å‹è¯„ä¼°"""
    # æ¨¡å‹åˆå§‹åŒ–
    model_path = os.path.expanduser(MODEL_PATH)
    model_name = get_model_name_from_path(model_path)
    tokenizer, model, processor, _ = load_pretrained_model(
        model_path, 
        model_base=None,
        model_name=model_name
    )
    
    # æ•°æ®åŠ è½½
    dataset = load_dataset(dataset_path, split="train")
    output_file = f"./results/answers_{os.path.basename(dataset_path)}.jsonl"
    
    # ç»“æœæ”¶é›†ï¼ˆä¿®å¤å­—æ®µï¼‰
    results = []
    for idx, sample in enumerate(tqdm(dataset, desc="Evaluating")):
        try:
            inputs, images, img_sizes, prompt = process_sample(
                sample, dataset_path,  # ä¼ é€’å½“å‰æ•°æ®é›†è·¯å¾„
                tokenizer, processor, model.config
            )
            
            with torch.inference_mode():
                outputs = model.generate(
                    inputs,
                    images=images,
                    image_sizes=img_sizes,
                    do_sample=GENERATION_TEMP > 0,
                    temperature=GENERATION_TEMP,
                    top_p=TOP_P,
                    num_beams=NUM_BEAMS,
                    max_new_tokens=MAX_TOKENS,
                    use_cache=True
                )
            
            answer = tokenizer.decode(outputs[0], skip_special_tokens=True).strip()
            
            results.append({
                "model_id": model_name,
                "image_id": sample["image_id"],
                "answer": answer,
                "gt_answer": sample["answer"],
                "category": sample["sub_task"],
                "options": sample["choices"]
            })
            
        except Exception as e:
            print(f"Error processing sample {idx}: {str(e)}")
    
    # ä¿å­˜ç»“æœ
    os.makedirs(os.path.dirname(output_file), exist_ok=True)
    with open(output_file, 'w') as f:
        for res in results:
            f.write(json.dumps(res) + '\n')
    
    # èµ„æºæ¸…ç†
    del model, tokenizer, processor
    torch.cuda.empty_cache()
    return output_file

def noise_experiment():
    """å™ªå£°é²æ£’æ€§å®éªŒä¸»æµç¨‹ï¼ˆä¿®å¤ç‰ˆæœ¬ï¼‰"""
    current_strength = INIT_STRENGTH
    torch.manual_seed(RANDOM_SEED)
    start_time = datetime.now().strftime("%Y%m%d_%H%M%S")
    
    try:
        while current_strength <= MAX_STRENGTH:
            # åˆ›å»ºå™ªå£°æ•°æ®é›†ç›®å½•
            noise_dir = f"./benchmark/Gaussian_{current_strength:.1f}"
            example_dir = f"./examples/Gaussian_{current_strength:.1f}"
            os.makedirs(noise_dir, exist_ok=True)
            os.makedirs(example_dir, exist_ok=True)
            
            # å¤åˆ¶å…ƒæ•°æ®ï¼ˆç¡®ä¿æŒ‡å‘å™ªå£°å›¾åƒï¼‰
            shutil.copy('metadata.csv', os.path.join(noise_dir, 'metadata.csv'))
            
            # åº”ç”¨å™ªå£°åˆ°æ–°ç›®å½•ï¼ˆå…³é”®è·¯å¾„ä¿®æ­£ï¼‰
            apply_noise(
                strength_factor=current_strength,
                input_image_path=CLEAN_IMAGE_DIR,
                output_image_path=os.path.join(noise_dir, "images"),  # æ­£ç¡®è¾“å‡ºè·¯å¾„
                example_image_path=example_dir,
                base_sigma=BASE_SIGMA,
                max_sigma=MAX_SIGMA,
                sigma_variation=SIGMA_VARIATION,
                gamma=GAMMA,
                random_seed=RANDOM_SEED,
                num_examples=NUM_EXAMPLES,
                num_workers=8,
                png_compression=0
            )
            
            # æ‰§è¡Œè¯„ä¼°ï¼ˆä½¿ç”¨å¸¦å™ªå£°çš„æ•°æ®é›†ï¼‰
            result_file = evaluate(noise_dir)
            
            # ============== æŒ‡æ ‡è®¡ç®— ==============
            strength_str = f"{current_strength:.1f}".replace('.', '_')
            metrics_csv = f"./results/metrics/Gaussian_{strength_str}_{start_time}.csv"
            os.makedirs(os.path.dirname(metrics_csv), exist_ok=True)
            
            # è®¡ç®—æŒ‡æ ‡
            compute_metrics(
                noise=f"Gaussian_{current_strength:.1f}",
                answers_file=result_file,
                output_file=f"./incorrect/incorrect_Gaussian_{strength_str}.csv",
                csv_file=metrics_csv,
                image_path_field='image_id',
                extra_outdir="./backup/metrics"
            )
            
            # è¯»å–æŒ‡æ ‡æ•°æ®
            try:
                metrics_df = pd.read_csv(metrics_csv)
                latest = metrics_df.iloc[-1]
                metrics = {
                    'overall': latest['æ€»ä½“å‡†ç¡®ç‡'],
                    'count': latest.get('Count_å‡†ç¡®ç‡', 0.0),
                    'location': latest.get('Relative location_å‡†ç¡®ç‡', 0.0)
                }
            except Exception as e:
                print(f"âš ï¸ æŒ‡æ ‡è¯»å–å¤±è´¥: {str(e)}")
                metrics = {'overall': 0.0, 'count': 0.0, 'location': 0.0}
            
            # ============== æ•°æ®è®°å½• ==============
            experiment_data['strengths'].append(current_strength)
            experiment_data['overall_acc'].append(metrics['overall'])
            experiment_data['count_acc'].append(metrics['count'])
            experiment_data['location_acc'].append(metrics['location'])
            
            # æ‰“å°çŠ¶æ€
            print(f"\n{' NOISE LEVEL ':=^60}")
            print(f"| {'å‚æ•°':<20} | {'å€¼':<36} |")
            print(f"| {'-'*18} | {'-'*34} |")
            print(f"| å™ªå£°å¼ºåº¦        | {current_strength:<10.1f} ({current_strength/MAX_STRENGTH:.0%}) |")
            print(f"| æ€»ä½“å‡†ç¡®ç‡      | {metrics['overall']:>10.2%} |")
            print(f"| è®¡æ•°å‡†ç¡®ç‡      | {metrics['count']:>10.2%} |")
            print(f"| å®šä½å‡†ç¡®ç‡      | {metrics['location']:>10.2%} |")
            print(f"| éšæœºåŸºå‡†çº¿      | {random_baseline['overall']:>10.2%} |")
            print(f"{'':=^60}")
            
            # ç»ˆæ­¢æ¡ä»¶
            if metrics['overall'] <= (random_baseline['overall'] + TOLERANCE):
                print(f"\nğŸ”´ å®éªŒç»ˆæ­¢ï¼šå½“å‰å‡†ç¡®ç‡ {metrics['overall']:.2%} â‰¤ åŸºå‡†çº¿ {random_baseline['overall']:.2%} + å®¹å¿åº¦ {TOLERANCE:.0%}")
                break
                
            current_strength = round(current_strength + STEP_SIZE, 1)
            
    except KeyboardInterrupt:
        print("\nğŸŸ¡ å®éªŒè¢«ç”¨æˆ·ä¸­æ–­")
    except Exception as e:
        print(f"\nğŸ”´ ä¸¥é‡é”™è¯¯: {str(e)}")
        raise
    finally:
        # ä¿å­˜æœ€ç»ˆç»“æœ
        os.makedirs(os.path.dirname(RESULT_CSV), exist_ok=True)
        pd.DataFrame(experiment_data).to_csv(RESULT_CSV, index=False)
        
        # ç”Ÿæˆå¸¦æ—¶é—´æˆ³çš„å¤‡ä»½
        backup_dir = f"./results/backups/{start_time}"
        os.makedirs(backup_dir, exist_ok=True)
        shutil.copy(RESULT_CSV, os.path.join(backup_dir, os.path.basename(RESULT_CSV)))
        
        print(f"\nâœ… å®éªŒæ•°æ®å·²ä¿å­˜è‡³: {os.path.abspath(RESULT_CSV)}")
        print(f"ğŸ”„ å·²åˆ›å»ºå¤‡ä»½å‰¯æœ¬: {os.path.abspath(backup_dir)}")
        torch.cuda.empty_cache()

def clear_previous_noise_data():
    """å®‰å…¨æ¸…ç†ä¹‹å‰çš„å™ªå£°æ•°æ®ï¼ˆä¿ç•™åŸå§‹æ•°æ®ï¼‰"""
    # ä»…åˆ é™¤Gaussian_å¼€å¤´çš„ç›®å½•
    noise_dirs = glob.glob(os.path.join("./benchmark", "Gaussian_*"))
    for dir_path in noise_dirs:
        if os.path.isdir(dir_path):
            print(f"æ¸…ç†æ—§æ•°æ®: {os.path.abspath(dir_path)}")
            shutil.rmtree(dir_path)

if __name__ == "__main__":
    # å‰ç½®æ£€æŸ¥
    required = {
        'metadata.csv': "å…ƒæ•°æ®æ–‡ä»¶",
        CLEAN_IMAGE_DIR: "å¹²å‡€å›¾åƒç›®å½•"
    }
    for path, desc in required.items():
        if not os.path.exists(path):
            raise FileNotFoundError(f"{desc}ä¸å­˜åœ¨: {os.path.abspath(path)}")

    # åˆå§‹åŒ–ç¯å¢ƒ
    torch.set_float32_matmul_precision('high')
    disable_torch_init()
    
    # æ¸…ç†å†å²æ•°æ®
    clear_previous_noise_data()
    
    # æ‰§è¡Œå®éªŒ
    noise_experiment()